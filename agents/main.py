import os
import asyncio
import psycopg
from psycopg import sql
from bs4 import BeautifulSoup
import requests
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ Docker/Render
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –î–∞–Ω–Ω—ã–µ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è
DATABASE_URL = os.getenv("DATABASE_URL")
AGENT_ID = os.getenv("AGENT_ID") # –ù–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ ID –∞–≥–µ–Ω—Ç–∞

async def get_config():
    """–ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–∑ –ë–î Neon (–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—É—Ä—Å–æ—Ä)"""
    try:
        async with await psycopg.AsyncConnection.connect(DATABASE_URL) as conn:
            async with conn.cursor() as cur:
                # –í —Ç–≤–æ–µ–π –±–∞–∑–µ –∫–æ–ª–æ–Ω–∫–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è num_agents
                await cur.execute(
                    "SELECT parse_link FROM agents WHERE num_agents = %s",
                    (AGENT_ID,)
                )
                row = await cur.fetchone()
                return row[0] if row else None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return None

async def save_result(table_name, column_name, product_name):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –¥–æ–±–∞–≤–ª–µ–Ω –∫—É—Ä—Å–æ—Ä –∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏)"""
    try:
        async with await psycopg.AsyncConnection.connect(DATABASE_URL) as conn:
            async with conn.cursor() as cur:
                # 1. –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É, –µ—Å–ª–∏ –Ω–µ—Ç (Self-healing)
                await cur.execute(sql.SQL("""
                    CREATE TABLE IF NOT EXISTS {} (
                        id BIGSERIAL PRIMARY KEY,
                        {} TEXT UNIQUE,
                        created_at TIMESTAMP DEFAULT NOW()
                    )
                """).format(sql.Identifier(table_name), sql.Identifier(column_name)))
                
                # 2. –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ (ON CONFLICT –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥—É–±–ª–∏)
                await cur.execute(sql.SQL("""
                    INSERT INTO {} ({}) VALUES (%s)
                    ON CONFLICT ({}) DO NOTHING
                """).format(
                    sql.Identifier(table_name), 
                    sql.Identifier(column_name),
                    sql.Identifier(column_name)
                ), (product_name,))
                
                await conn.commit()
                logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {product_name} –≤ {table_name}")
    except Exception as e:
        logger.error(f"–û–®–ò–ë–ö–ê —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")

def parse_page(url, search_terms):
    """–†–µ–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∏–∑ —Ç–≤–æ–µ–π —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏)"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        page_text = soup.get_text().lower()
        
        found = [term for term in search_terms if term.lower() in page_text]
        return list(set(found)) # –¢–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞—Ö–æ–¥–∫–∏
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
        return []

async def run_worker():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª (–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ª–æ–≥–∏–∫–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è)"""
    if not AGENT_ID or not DATABASE_URL:
        logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –ù–µ –∑–∞–¥–∞–Ω—ã AGENT_ID –∏–ª–∏ DATABASE_URL")
        return

    logger.info(f"üöÄ –í–æ—Ä–∫–µ—Ä {AGENT_ID} –Ω–∞—á–∞–ª —Ä–∞–±–æ—Ç—É")
    
    parse_url = await get_config()
    if not parse_url:
        logger.warning(f"–ó–∞–¥–∞–Ω–∏–µ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ {AGENT_ID} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
        return

    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞ (–º–æ–∂–Ω–æ –ø–æ–∑–∂–µ —Ç–æ–∂–µ –≤—ã–Ω–µ—Å—Ç–∏ –≤ –ë–î)
    categories = {
        "fruits": ["–Ø–±–ª–æ–∫–æ", "–ë–∞–Ω–∞–Ω", "–ê–ø–µ–ª—å—Å–∏–Ω", "–ì—Ä—É—à–∞"],
        "vegetables": ["–ö–∞—Ä—Ç–æ—Ñ–µ–ª—å", "–ú–æ—Ä–∫–æ–≤—å", "–ü–æ–º–∏–¥–æ—Ä"],
        "fish": ["–õ–æ—Å–æ—Å—å", "–¢—É–Ω–µ—Ü"]
    }
    
    for category, terms in categories.items():
        logger.info(f"üîé –ü–æ–∏—Å–∫ {category} –Ω–∞ {parse_url}...")
        found_items = parse_page(parse_url, terms)
        
        for item in found_items:
            await save_result(category, category, item)

    logger.info(f"üèÅ –í–æ—Ä–∫–µ—Ä {AGENT_ID} –∑–∞–≤–µ—Ä—à–∏–ª –∑–∞–¥–∞—á—É")

if __name__ == "__main__":
    asyncio.run(run_worker())